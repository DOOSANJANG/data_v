pprob=exp(peta)/(1+exp(peta))
c=sort(pprob)
B=length(c)
tclass=ty
for(k in (1:B)){
dclass=as.numeric(pprob>c[k])
roc[k,2]=sum((dclass==1)&(tclass==1))/sum(tclass==1)
roc[k,1]=sum((dclass==1)&(tclass==0))/sum(tclass==0)
}
plot(roc[,1],roc[,2],type="l")
abline(0,1,col="red")
## Correct model
glm.fit=glm(y~x[,1:2],family=binomial)
est=as.numeric(glm.fit$coefficients)
peta=est[1]+tx[,1:2]%*%est[2:3]
pprob=exp(peta)/(1+exp(peta))
c=sort(pprob)
B=length(c)
tclass=ty
#
# Y-axis = Sensitivity = True positive rate
#         =TP/P= TP/(TP+FN)
# X-axis = 1-Specificity= False postive rate
#          =FP/N = FP/(TN+FP)
#
#
roc=matrix(0,B,2)
for(k in (1:B)){
dclass=as.numeric(pprob>c[k])
roc[k,2]=sum((dclass==1)&(tclass==1))/sum(tclass==1)
roc[k,1]=sum((dclass==1)&(tclass==0))/sum(tclass==0)
}
plot(roc[,1],roc[,2],type="p")
abline(0,1,col="red")
glm.fit=glm(y~x,family=binomial)
est=as.numeric(glm.fit$coefficients)
peta=est[1]+tx%*%est[2:11]
pprob=exp(peta)/(1+exp(peta))
c=sort(pprob)
B=length(c)
tclass=ty
for(k in (1:B)){
dclass=as.numeric(pprob>c[k])
roc[k,2]=sum((dclass==1)&(tclass==1))/sum(tclass==1)
roc[k,1]=sum((dclass==1)&(tclass==0))/sum(tclass==0)
}
plot(roc[,1],roc[,2],type="l")
abline(0,1,col="red")
## Correct model
glm.fit=glm(y~x[,1:2],family=binomial)
est=as.numeric(glm.fit$coefficients)
peta=est[1]+tx[,1:2]%*%est[2:3]
pprob=exp(peta)/(1+exp(peta))
c=sort(pprob)
B=length(c)
tclass=ty
#
# Y-axis = Sensitivity = True positive rate
#         =TP/P= TP/(TP+FN)
# X-axis = 1-Specificity= False postive rate
#          =FP/N = FP/(TN+FP)
#
#
roc=matrix(0,B,2)
for(k in (1:B)){
dclass=as.numeric(pprob>c[k])
roc[k,2]=sum((dclass==1)&(tclass==1))/sum(tclass==1)
roc[k,1]=sum((dclass==1)&(tclass==0))/sum(tclass==0)
}
plot(roc[,1],roc[,2],type="p")
abline(0,1,col="red")
n=100
y=rbinom(n,1,0.5)
x=matrix(rnorm(n*10),n,10)
eta= x[,1]+x[,2]
probs=exp(eta)/(1+exp(eta))
for(i in (1:n)){
y[i]=rbinom(1,1,probs[i])
}
m=100
ty=rbinom(n,1,0.5)
tx=matrix(rnorm(n*10),n,10)
teta=tx[,1]+tx[,2]
tprobs=exp(teta)/(1+exp(teta))
for(i in (1:n)){
ty[i]=rbinom(1,1,tprobs[i])
}
glm.fit=glm(y~x,family=binomial)
est=as.numeric(glm.fit$coefficients)
peta=est[1]+tx%*%est[2:11]
pprob=exp(peta)/(1+exp(peta))
c=sort(pprob)
B=length(c)
tclass=ty
for(k in (1:B)){
dclass=as.numeric(pprob>c[k])
roc[k,2]=sum((dclass==1)&(tclass==1))/sum(tclass==1)
roc[k,1]=sum((dclass==1)&(tclass==0))/sum(tclass==0)
}
plot(roc[,1],roc[,2],type="l")
abline(0,1,col="red")
library(ISLR)
attach(Smarket)
for(k in (1:B)){
dclass=as.numeric(pprob>c[k])
roc[k,2]=sum((dclass==1)&(tclass==1))/sum(tclass==1)
roc[k,1]=sum((dclass==1)&(tclass==0))/sum(tclass==0)
}
plot(roc[,1],roc[,2],type="l")
abline(0,1,col="red")
glm.fit=glm(y~x[,1:2],family=binomial)
est=as.numeric(glm.fit$coefficients)
peta=est[1]+tx[,1:2]%*%est[2:3]
pprob=exp(peta)/(1+exp(peta))
c=sort(pprob)
B=length(c)
tclass=ty
#
# Y-axis = Sensitivity = True positive rate
#         =TP/P= TP/(TP+FN)
# X-axis = 1-Specificity= False postive rate
#          =FP/N = FP/(TN+FP)
#
#
roc=matrix(0,B,2)
for(k in (1:B)){
dclass=as.numeric(pprob>c[k])
roc[k,2]=sum((dclass==1)&(tclass==1))/sum(tclass==1)
roc[k,1]=sum((dclass==1)&(tclass==0))/sum(tclass==0)
}
plot(roc[,1],roc[,2],type="p")
abline(0,1,col="red")
par(mfrow =  c(1,2))
glm.fit=glm(y~x,family=binomial)
est=as.numeric(glm.fit$coefficients)
peta=est[1]+tx%*%est[2:11]
pprob=exp(peta)/(1+exp(peta))
c=sort(pprob)
B=length(c)
tclass=ty
#
# Y-axis = Sensitivity = True positive rate
#         =TP/P= TP/(TP+FN)
# X-axis = 1-Specificity= False postive rate
#          =FP/N = FP/(TN+FP)
#
#
for(k in (1:B)){
dclass=as.numeric(pprob>c[k])
roc[k,2]=sum((dclass==1)&(tclass==1))/sum(tclass==1)
roc[k,1]=sum((dclass==1)&(tclass==0))/sum(tclass==0)
}
plot(roc[,1],roc[,2],type="l")
abline(0,1,col="red")
glm.fit=glm(y~x[,1:2],family=binomial)
est=as.numeric(glm.fit$coefficients)
peta=est[1]+tx[,1:2]%*%est[2:3]
pprob=exp(peta)/(1+exp(peta))
c=sort(pprob)
B=length(c)
tclass=ty
#
# Y-axis = Sensitivity = True positive rate
#         =TP/P= TP/(TP+FN)
# X-axis = 1-Specificity= False postive rate
#          =FP/N = FP/(TN+FP)
#
#
roc=matrix(0,B,2)
for(k in (1:B)){
dclass=as.numeric(pprob>c[k])
roc[k,2]=sum((dclass==1)&(tclass==1))/sum(tclass==1)
roc[k,1]=sum((dclass==1)&(tclass==0))/sum(tclass==0)
}
plot(roc[,1],roc[,2],type="p")
abline(0,1,col="red")
library(ISLR)
attach(Smarket)
n=100
y=rbinom(n,1,0.5)
x=matrix(rnorm(n*10),n,10)
eta= x[,1]+x[,2]
probs=exp(eta)/(1+exp(eta))
for(i in (1:n)){
y[i]=rbinom(1,1,probs[i])
}
m=100
ty=rbinom(n,1,0.5)
tx=matrix(rnorm(n*10),n,10)
teta=tx[,1]+tx[,2]
tprobs=exp(teta)/(1+exp(teta))
for(i in (1:n)){
ty[i]=rbinom(1,1,tprobs[i])
}
par(mfrow =  c(1,2))
## All variables
glm.fit=glm(y~x,family=binomial)
est=as.numeric(glm.fit$coefficients)
peta=est[1]+tx%*%est[2:11]
pprob=exp(peta)/(1+exp(peta))
c=sort(pprob)
B=length(c)
tclass=ty
#
# Y-axis = Sensitivity = True positive rate
#         =TP/P= TP/(TP+FN)
# X-axis = 1-Specificity= False postive rate
#          =FP/N = FP/(TN+FP)
#
#
for(k in (1:B)){
dclass=as.numeric(pprob>c[k])
roc[k,2]=sum((dclass==1)&(tclass==1))/sum(tclass==1)
roc[k,1]=sum((dclass==1)&(tclass==0))/sum(tclass==0)
}
plot(roc[,1],roc[,2],type="l")
abline(0,1,col="red")
library(ISLR)
attach(Smarket)
n=100
y=rbinom(n,1,0.5)
x=matrix(rnorm(n*10),n,10)
eta= x[,1]+x[,2]
probs=exp(eta)/(1+exp(eta))
for(i in (1:n)){
y[i]=rbinom(1,1,probs[i])
}
m=100
ty=rbinom(n,1,0.5)
tx=matrix(rnorm(n*10),n,10)
teta=tx[,1]+tx[,2]
tprobs=exp(teta)/(1+exp(teta))
for(i in (1:n)){
ty[i]=rbinom(1,1,tprobs[i])
}
## All variables
glm.fit=glm(y~x,family=binomial)
est=as.numeric(glm.fit$coefficients)
peta=est[1]+tx%*%est[2:11]
pprob=exp(peta)/(1+exp(peta))
c=sort(pprob)
B=length(c)
tclass=ty
#
# Y-axis = Sensitivity = True positive rate
#         =TP/P= TP/(TP+FN)
# X-axis = 1-Specificity= False postive rate
#          =FP/N = FP/(TN+FP)
#
#
for(k in (1:B)){
dclass=as.numeric(pprob>c[k])
roc[k,2]=sum((dclass==1)&(tclass==1))/sum(tclass==1)
roc[k,1]=sum((dclass==1)&(tclass==0))/sum(tclass==0)
}
par(mfrow =  c(1,2))
plot(roc[,1],roc[,2],type="l")
abline(0,1,col="red")
## Correct model
glm.fit=glm(y~x[,1:2],family=binomial)
est=as.numeric(glm.fit$coefficients)
peta=est[1]+tx[,1:2]%*%est[2:3]
pprob=exp(peta)/(1+exp(peta))
c=sort(pprob)
B=length(c)
tclass=ty
#
# Y-axis = Sensitivity = True positive rate
#         =TP/P= TP/(TP+FN)
# X-axis = 1-Specificity= False postive rate
#          =FP/N = FP/(TN+FP)
#
#
roc=matrix(0,B,2)
for(k in (1:B)){
dclass=as.numeric(pprob>c[k])
roc[k,2]=sum((dclass==1)&(tclass==1))/sum(tclass==1)
roc[k,1]=sum((dclass==1)&(tclass==0))/sum(tclass==0)
}
plot(roc[,1],roc[,2],type="p")
abline(0,1,col="red")
n=100
y=rbinom(n,1,0.5)
x=matrix(rnorm(n*10),n,10)
eta= x[,1]+x[,2]
probs=exp(eta)/(1+exp(eta))
for(i in (1:n)){
y[i]=rbinom(1,1,probs[i])
}
m=100
ty=rbinom(n,1,0.5)
tx=matrix(rnorm(n*10),n,10)
teta=tx[,1]+tx[,2]
tprobs=exp(teta)/(1+exp(teta))
for(i in (1:n)){
ty[i]=rbinom(1,1,tprobs[i])
}
## All variables
glm.fit=glm(y~x,family=binomial)
est=as.numeric(glm.fit$coefficients)
peta=est[1]+tx%*%est[2:11]
pprob=exp(peta)/(1+exp(peta))
c=sort(pprob)
B=length(c)
tclass=ty
#
# Y-axis = Sensitivity = True positive rate
#         =TP/P= TP/(TP+FN)
# X-axis = 1-Specificity= False postive rate
#          =FP/N = FP/(TN+FP)
#
#
for(k in (1:B)){
dclass=as.numeric(pprob>c[k])
roc[k,2]=sum((dclass==1)&(tclass==1))/sum(tclass==1)
roc[k,1]=sum((dclass==1)&(tclass==0))/sum(tclass==0)
}
par(mfrow =  c(1,2))
plot(roc[,1],roc[,2],type="l")
abline(0,1,col="red")
glm.fit=glm(y~x[,1:2],family=binomial)
est=as.numeric(glm.fit$coefficients)
peta=est[1]+tx[,1:2]%*%est[2:3]
pprob=exp(peta)/(1+exp(peta))
c=sort(pprob)
B=length(c)
tclass=ty
#
# Y-axis = Sensitivity = True positive rate
#         =TP/P= TP/(TP+FN)
# X-axis = 1-Specificity= False postive rate
#          =FP/N = FP/(TN+FP)
#
#
roc=matrix(0,B,2)
for(k in (1:B)){
dclass=as.numeric(pprob>c[k])
roc[k,2]=sum((dclass==1)&(tclass==1))/sum(tclass==1)
roc[k,1]=sum((dclass==1)&(tclass==0))/sum(tclass==0)
}
plot(roc[,1],roc[,2],type="p")
abline(0,1,col="red")
for(k in (1:B)){
dclass=as.numeric(pprob>c[k])
roc[k,2]=sum((dclass==1)&(tclass==1))/sum(tclass==1)
roc[k,1]=sum((dclass==1)&(tclass==0))/sum(tclass==0)
}
par(mfrow =  c(1,2))
plot(roc[,1],roc[,2],type="p")
abline(0,1,col="red")
## Correct model
glm.fit=glm(y~x[,1:2],family=binomial)
est=as.numeric(glm.fit$coefficients)
peta=est[1]+tx[,1:2]%*%est[2:3]
pprob=exp(peta)/(1+exp(peta))
c=sort(pprob)
B=length(c)
tclass=ty
#
# Y-axis = Sensitivity = True positive rate
#         =TP/P= TP/(TP+FN)
# X-axis = 1-Specificity= False postive rate
#          =FP/N = FP/(TN+FP)
#
#
roc=matrix(0,B,2)
for(k in (1:B)){
dclass=as.numeric(pprob>c[k])
roc[k,2]=sum((dclass==1)&(tclass==1))/sum(tclass==1)
roc[k,1]=sum((dclass==1)&(tclass==0))/sum(tclass==0)
}
plot(roc[,1],roc[,2],type="p")
abline(0,1,col="red")
glm.fit=glm(y~x,family=binomial)
est=as.numeric(glm.fit$coefficients)
peta=est[1]+tx%*%est[2:11]
pprob=exp(peta)/(1+exp(peta))
c=sort(pprob)
B=length(c)
tclass=ty
#
# Y-axis = Sensitivity = True positive rate
#         =TP/P= TP/(TP+FN)
# X-axis = 1-Specificity= False postive rate
#          =FP/N = FP/(TN+FP)
#
#
for(k in (1:B)){
dclass=as.numeric(pprob>c[k])
roc[k,2]=sum((dclass==1)&(tclass==1))/sum(tclass==1)
roc[k,1]=sum((dclass==1)&(tclass==0))/sum(tclass==0)
}
par(mfrow =  c(1,2))
plot(roc[,1],roc[,2],type="p")
abline(0,1,col="red")
glm.fit=glm(y~x[,1:2],family=binomial)
est=as.numeric(glm.fit$coefficients)
peta=est[1]+tx[,1:2]%*%est[2:3]
pprob=exp(peta)/(1+exp(peta))
c=sort(pprob)
B=length(c)
tclass=ty
#
# Y-axis = Sensitivity = True positive rate
#         =TP/P= TP/(TP+FN)
# X-axis = 1-Specificity= False postive rate
#          =FP/N = FP/(TN+FP)
#
#
roc=matrix(0,B,2)
for(k in (1:B)){
dclass=as.numeric(pprob>c[k])
roc[k,2]=sum((dclass==1)&(tclass==1))/sum(tclass==1)
roc[k,1]=sum((dclass==1)&(tclass==0))/sum(tclass==0)
}
plot(roc[,1],roc[,2],type="p")
abline(0,1,col="red")
setwd("~/GitHub/data_v/170822")
german = read.csv(file = german_numeric.csv)
german = read.csv('file = german_numeric.csv')
german = read.csv('file = 170822\german_numeric.csv')
german = read.csv('file = 170822/german_numeric.csv')
german = read.csv('file = /170822/german_numeric.csv')
german = read.csv('file = german_numeric.csv')
german = read.csv('german_numeric.csv')
Vier(german)
View(german)
data(german)
german = read.csv('german_numeric.csv', header = T)
data(german)
german
head(german)
german = read.csv('german_numeric.csv', header = T)
names(german)
dim(german)
summary(german)
library(class)
dim(german)
train = c(1:600)
test = c(601:1000)
german[,16] <- german[,16]-1
Response <- rep(0,1000)
for (i in c(1:1000))
{
if (german[i,16]==0){Response[i]='Good'}
else {Response[i]='Bad'}
}
attach(german)
train.x = german[train,-16]
test.x = german[test,-16]
train.result = Result[train]
test.result = Result[test]
train.result
test.result
set.seed(1)
glm.fit-glm(Result~.,data=german,family=binomial)
attach(german)
glm.fit-glm(Result~.,data=german,family=binomial)
glm.fit<-glm(Result~.,data=german,family=binomial)
glm.fit
summary(glm.fit)
coef(glm.fit)
summary(glm.fit)$coef
glm.probs = predict(glm.fit, type = 'reponse')
glm.probs = predict(glm.fit, type = "reponse")
glm.probs = predict(glm.fit, type = "response")
glm.probs
glm.porbs[1:10]
glm.probs[1:10]
glm.pred=rep("Good",1000)
glm.pred
glm.pred[glm.probs>0.5]='Bad'
table(glm.pred,Response)
(137+629)/1000
mean(glm.pred==Response)
glm.probs[1:10]
glm.probs = predict(glm.fit, type = "response")
glm.probs
library(MASS)
lda.fit = lda(Result ~.,data = german, subset = train)
lda.pred = predict(lda.fit, test.x)
lda.pred
lda.fit
lda.pred = predict(lda.fit, test.x)
lda.pred
summary(lda.class)
summary(lda.pred)
names(lda.pred)
table)lda.class,test.result
table(lda.class,test.result)
lda.class=lda.pred$class
table(lda.class,test.result)
summary(lda.class)
table(lda.class,test.result)
mean(lda.clas==teset.result)
mean(lda.class==teset.result)
mean(lda.class==test.result)
mean(lda.class !=test.result)
mean(lda.class==test.result)
table(lda.class,test.result)
(61+34)/400
qda.fit = qda(Result ~ ., data = german, subset = train)
qda.pred = predict(qda.fit, test.x)
qda.class=qda.pred$class
mean(qda.pred$class != test.result)
mean(qda.class==test.result)
table(qda.class,test.reslut)
table(qda.class,test.result)
(216+75)/400
mean(glm.pred)
mean(glm.pred>0)
glm.pred
