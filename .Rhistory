for(k in (1:B)){
n0=10000
n1=n0*r
n=n0+n1
x=c(rep(0,n0),rep(1,n1))
eta=exp(beta0+beta1*x)
prob=eta/(1+eta)
y=rep(0,n)}
}
B=100
est=matrix(0,B,3)
r=0.1
beta0=-5
beta1=1
for(k in (1:B)){
n0=10000
n1=n0*r
n=n0+n1
x=c(rep(0,n0),rep(1,n1))
}
x
eta=exp(beta0+beta1*x)
prob=eta/(1+eta)
y=rep(0,n)
for(i in (1:n)){
y[i]=rbinom(1,1,prob[i])
}
B=100
est=matrix(0,B,3)
r=0.1
beta0=-5
beta1=1
for(k in (1:B)){
n0=10000
n1=n0*r
n=n0+n1
x=c(rep(0,n0),rep(1,n1))
eta=exp(beta0+beta1*x)
prob=eta/(1+eta)
y=rep(0,n)
for(i in (1:n)){
y[i]=rbinom(1,1,prob[i])
}
glm.fit=glm(y~x,family=binomial)
est[k,1]=sum(y)/n*100
est[k,2:3]=as.vector(glm.fit$coefficients)
cat("\n")
cat(k)
}
apply(est,2,mean)
apply(est,2,var)
beta0=-7
apply(est,2,mean)
apply(est,2,var)
for(k in (1:B)){
n0=10000
n1=n0*r
n=n0+n1
x=c(rep(0,n0),rep(1,n1))
eta=exp(beta0+beta1*x)
prob=eta/(1+eta)
y=rep(0,n)
for(i in (1:n)){
y[i]=rbinom(1,1,prob[i])
}
glm.fit=glm(y~x,family=binomial)
est[k,1]=sum(y)/n*100
est[k,2:3]=as.vector(glm.fit$coefficients)
cat("\n")
cat(k)
}
apply(est,2,mean)
apply(est,2,var)
B=100
est=matrix(0,B,3)
r=0.1
beta0=-5
beta1=1
B=200
nums=rep(0,200)
for(k in (1:B)){
n=300
y=rbinom(n,1,0.5)
x=matrix(rnorm(n*100),n,100)
fullmod = glm(y~x,family=binomial)
pval=coef(summary(fullmod))[,4]
nums[k]=sum(pval<0.05)
}
B=200
nums=rep(0,200)
for(k in (1:B)){
n=300
y=rbinom(n,1,0.5)
x=matrix(rnorm(n*100),n,100)
fullmod = glm(y~x,family=binomial)
pval=coef(summary(fullmod))[,4]
nums[k]=sum(pval<0.05)
}
nums
summary(nums)
nums
count(nums)
length(nums)
pval
nums
summary(nums)
y
y
y
n=200
y=rbinom(n,1,0.5)
x=matrix(rnorm(n*100),n,100)
fullmod = glm(y~x,family=binomial)
summary(fullmod)
nothing <- glm(y ~ 1,family=binomial)
summary(nothing)
n=200
y=rbinom(n,1,0.5)
x=matrix(rnorm(n*100),n,100)
fullmod = glm(y~x,family=binomial)
summary(fullmod)
nothing <- glm(y ~ 1,family=binomial)
summary(nothing)
backwards = step(fullmod)
backwards = step(fullmod,trace=0)
formula(backwards)
summary(backwards)
n=200
y=rbinom(n,1,0.5)
x=matrix(rnorm(n*100),n,100)
fullmod = glm(y~x,family=binomial)
summary(fullmod)
nothing <- glm(y ~ 1,family=binomial)
summary(nothing)
backwards = step(fullmod)
backwards = step(fullmod,trace=0)
formula(backwards)
summary(backwards)
summary
summary
n=200
y=rbinom(n,1,0.5)
x=matrix(rnorm(n*100),n,100)
fullmod = glm(y~x,family=binomial)
summary(fullmod)
x
a1=add1(glm(y~x[,1]+x[,2]+x[,3]),y~x[,1]+x[,2]+x[,3]
+x[,4]+x[,5],test="F")
d1=drop1(glm(y~x[,1]+x[,2]+x[,3]),y~x[,1]
+x[,2]+x[,3],test="F")
library(MASS)
for(k in (1:B)){
dclass=as.numeric(pprob>c[k])
roc[k,2]=sum((dclass==1)&(tclass==1))/sum(tclass==1)
roc[k,1]=sum((dclass==1)&(tclass==0))/sum(tclass==0)
}
plot(roc[,1],roc[,2],type="l")
abline(0,1,col="red")
plot(roc[,1],roc[,2],type="l")
library(ISLR)
attach(Smarket)
for(k in (1:B)){
dclass=as.numeric(pprob>c[k])
roc[k,2]=sum((dclass==1)&(tclass==1))/sum(tclass==1)
roc[k,1]=sum((dclass==1)&(tclass==0))/sum(tclass==0)
}
plot(roc[,1],roc[,2],type="l")
abline(0,1,col="red")
library(ISLR)
attach(Smarket)
train=(Year<2005)
Smarket.2005=Smarket[!train,]
dim(Smarket.2005)
glm.fit=glm(Direction~Lag1+Lag2+Lag3+
Lag4+Lag5+Volume,family=binomial,subset=train)
glm.probs=predict(glm.fit,Smarket.2005,type="response")
probs=as.numeric(glm.probs)
tclass=as.numeric(Direction[!train])
c=sort(probs)
B=length(c)
roc=matrix(0,B,2)
for(k in (1:B)){
dclass=as.numeric(probs>c[k])
roc[k,2]=sum((dclass==1)&(tclass==2))/sum(tclass==2)
roc[k,1]=sum((dclass==1)&(tclass==1))/sum(tclass==1)
}
plot(roc[,1],roc[,2],type="l")
abline(0,1,col="red")
rm(list = ls())
x=rnorm(50)
x
plot(x)
predict(x)
lm(x)
rm(list = ls())
x = rnorm(50)
y = x + rnorm(50, mean=50, sd=0.1)
y
cor(x,y)
x = rnorm(50)
y = x + rnorm(50, mean=50, sd=0.1)
cor(x,y)
x = rnorm(50)
y = x + rnorm(50, mean=50, sd=0.1)
cor(x,y)
set.seed(1)
x = rnorm(50)
y = x + rnorm(50, mean=50, sd=0.1)
cor(x,y)
set.seed(1)
x = rnorm(50)
y = x + rnorm(50, mean=50, sd=0.1)
cor(x,y)
sd(x)
var(x)
set.seed(1)
x=rnorm(100)
y=rnorm(100)
plot(x,y, xlab = 'test x', ylab = 'test y', main = 'test plot', col = 'red')
set.seed(1)
x=rnorm(100)
y=rnorm(100)
plot(x,y, xlab = 'test x', ylab = 'test y', main = 'test plot', col = 'red', pch = 20)
lm(y~x)
lm.fit=lm(y~x)
abline(lm.fit)
x=seq(-pi, pi, length=50)
x
f <- outer(x,y, function(x,y)cos(y)/(1+x^2))
y=x
f <- outer(x,y, function(x,y)cos(y)/(1+x^2))
x=1:10
y=x
f <- outer(x,y, function(x,y)cos(y)/(1+x^2))
f
?outer
y
contour(x,y,f)
contour(x,y,f, nlevels = 45,add=T)
image(x,y,f)
image(x,y,f, nlevels = 45, add=T)
image(x,y,f)
contour(x,y,f, nlevels = 45,add=T)
contour(x,y,f, nlevels = 45,add=F)
contour(x,y,f, nlevels = 10,add=T)
image(x,y,f)
contour(x,y,f, nlevels = 10,add=T)
x=1:10
y=x
f <- outer(x,y, function(x,y)cos(y)/(1+x^2))
contour(x,y,f, nlevels = 10,add=T)
x=1:10
y=x
f <- outer(x,y, function(x,y)cos(y)/(1+x^2))
contour(x,y,f, nlevels = 10,add=T)
contour(x,y,f, nlevels = 10)
contour(x,y,f, nlevels = 10)
image(x,y,f)
contour(x,y,f, nlevels = 10)
image(x,y,f)
contour(x,y,f, nlevels = 10, add=T)
contour(x,y,f, nlevels = 10, add=T, xlim = 4, ylim = 4)
image(x,y,f)
image(x,y,f, xlim = 4, ylim = 4)
image(x,y,f, xlim = 4, ylim = 4)
image(x,y,f)
persp(x,y,f)
persp(x,y,f, theta=30)
persp(x,y,f, theta=30, phi=20)
persp(x,y,f, theta=30, phi=40)
persp(x,y,f, theta=30, phi=1)
persp(x,y,f, theta=30, phi=80)
persp(x,y,f, theta=30, phi=30)
persp(x,y,f, theta=45, phi=45)
library(ISLR)
data(Auto)
dim(Auto)
AUto[1:4,]
attach(Auto)
AUto[1:4,]
attach(Auto)
Auto[1:4,]
names(AUto)
names(Auto)
AUto = na.omit[Auto]
AUto = na.omit(Auto)
head(Auto)
plot(cylinders, mpg)
cylinders = as.factor(cylinders)
cylinders
plot(cylinders, mpg)
plot(cylinders, mpg, col='red', varwidth=T)
plot(cylinders, mpg, col='red', varwidth=F)
plot(cylinders, mpg, col='red', varwidth=T)
plot(cylinders, mpg, col='red', varwidth=T, horizental=T)
plot(cylinders, mpg, col='red', varwidth=T, horizontal=T)
plot(cylinders, mpg, col='red', varwidth=T, horizontal=F)
hist(mpg)
hist(Cylinders)
hist(cylinders)
hist(mpg, breaks=15)
pairs(Auto)
pairs(~mpg+displacement+horsepower)
plot(horsepower, mpg)
identify(horsepower, mpg, name)
A=matrix(c(1,2,0,0,3,0,2,-4,2),nrow=3,byrow=TRUE)
A
eigen(A)
B=eigen(A)
B$values*B$vectors
B$vectors
B$values
diag(B$values)
diag(B$values)*B$vectors
diag(B$values)%*%B$vectors
diag(B$values)%*%t(B$vectors)
value=B$values
vector=B$values
value=B$values
vector=B$vectors
value=diag(B$values)
value
vector
A<-matrix(c(1,0,0,0,2,0,0,3,0,0,0,0,0,0,0,0,2,0,0,0),nrow=4,byrow=TRUE)
A
A
res
res<-svd(A)
res
res$u%*%res$d%*%t(res$v)
res$u%*%diag(res$d)%*%t(res$v)
eigen(A)
A
A
eigen(A)
library(ISLR)
attach(Hitters)
data(Hitters)
Hitters
Value(Hitters)
names(Hitters)
head(Hitters)
library(MASS)
attach(Auto)
head(Auto)
library(MASS)
attach(Auto)
head(Auto)
set.seed(1)
trainx<-sample(392,392*0.5)
trainx
lm.fit <- lm(mpg~horsepower, data=Auto,  subset = train)
trainx<-sample(392,392*0.5)
lm.fit <- lm(mpg~horsepower, data=Auto, subset = train)
lm.fit <- lm(mpg~horsepower, data=Auto, subset = trainx)
predict(lm.fit, Auto[-trainx,])
lm.fit
set.seed(1)
trainx<-sample(392,392*0.5)
lm.fit <- lm(mpg~horsepower, data=Auto, subset = trainx)
lm.fit
(mpg[-train]-predict(lm.fit, Auto[-trainx,]))^2
(mpg[-trainx]-predict(lm.fit, Auto[-trainx,]))^2
mean((mpg[-trainx]-predict(lm.fit, Auto[-trainx,]))^2)
set.seed(1)
trainx<-sample(392,392*0.5)
lm.fit <- lm(mpg~horsepower, data=Auto, subset = trainx)
predict(lm.fit, Auto[-trainx,])
mean((mpg[-trainx]-predict(lm.fit, Auto[-trainx,]))^2)
mpg[-trainx]
mpg[trainx]
trainx<-sample(392,392*0.5)
lm.fit2 <- lm(mpg~poly(horsepower,2), subset = trainx)
mean((mpg[-trainx]-predict(lm.fit2, Auto[-trainx,]))^2)
lm.fit3 <- lm(mpg~poly(horsepower,3), subset = trainx)
mean((mpg[-trainx]-predict(lm.fit3, Auto[-trainx,]))^2)
mean((mpg[-trainx]-predict(lm.fit2, Auto[-trainx,]))^2)
glm.fit <- glm(mpg~horsepower, data=auto)
glm.fit <- glm(mpg~horsepower, data=Auto)
coef(glm.fit)
cv.err=cv.glm(auto, glm.fit)
cv.err=cv.glm(Auto, glm.fit)
library(boot)
cv.err=cv.glm(Auto, glm.fit)
cv.err
cv.err$call
cv.err$K
cv.err$delta
glm.fit2=glm(mpg~poly(horsepower, 2))
cv.err2=cv.glm(Auto,glm.fit2)
glm.fit3=glm(mpg~poly(horsepower, 3))
cv.err3=cv.glm(Auto,glm.fit3)
cv.err3
cv.err3$delta
alpha.fn=function(data,index{
X=data$X[index]
Y=data$Y[index]
return((var(X)-cov(X,Y))/(var((V)+var(Y)-2*cov(X,Y))))
})
alpha.fn=function(data,index){
X=data$X[index]
Y=data$Y[index]
return((var(X)-cov(X,Y))/(var((V)+var(Y)-2*cov(X,Y))))
}
alpha.fn(Portfolio, 1:100)
alpha.fn=function(data,index){
X=data$X[index]
Y=data$Y[index]
return((var(X)-cov(X,Y))/(var((X)+var(Y)-2*cov(X,Y))))
}
alpha.fn(Portfolio, 1:100)
return(coef(lm(mpg~horsepower,data=data,subset=index)))
boot.fn=function(data,index)
{return(coef(lm(mpg~horsepower,data=data,subset=index)))}
boot(Auto,boot.fn,1000)
boot(Auto,boot.fn,1000)
summary(lm(mpg~horsepower,data=Auto))$coef
boot(Auto,boot.fn,5000)
summary(lm(mpg~horsepower,data=Auto))$coef
trainx
predict(lm.fit, Auto[-trainx])
predict(lm.fit, Auto[-trainx,])
predict(lm.fit, Auto[-trainx])
predict(lm.fit, Auto[-trainx,])
trainx
Auto[trainx]
Auto[trainx,]
Auto[-trainx,]
mpg[-trainx]
aaa = c(1,2,3,4)
poly(aaa, 2)
aaa
aaa = as.factor(c(1,2,3,4))
poly(aaa, 2)
aaa = data.frame(c(1,2,3,4))
poly(aaa, 2)
aaa = table(c(1,2,3,4))
poly(aaa, 2)
aaa = c(1,2,3,4)
poly(aaa, 2)
poly(aaa, 3)
library(ISLR)
names(Hitters)
dim(Hitters)
str(Hitters)
sum(is.na(Hitters$Salary))
Hitters=na.omit(Hitters)
dim(Hitters)
sum(is.na(Hitters))
library(leaps)
regfit.full=regsubsets(Salary~., Hitters)
summary(regfit.full)
reg.summary=summary(regfit.full)
reg.summary$rsq
names(reg.summary)
reg.summary
names(reg.summary)
reg.summary$rsq
regfit.fwd=regsubsets(Salary~.,data=Hitters,nvmax=19,method="forward")
regfit.fwd
summary(regfit.fwd)
library(glmnet)
X
x
x=model.matrix(Salary~.,Hitters)[,-1]
y=Hitters$Salary
grid=10^seq(10,-2,length=100)
y=Hitters$Salary
grid
predict(ridge.mod, s=05, type="coefficients")
ridge.mod=glmnet(x,y,alpha=0,lambda=grid) #lambda <- 허용 벡터 크기(람다, ex. b1 + b2 < c(람다)) / alpha -> 0에서 1값을 가짐 (라그랑쥬 승수법), 0(능선), 1(라소), 0~1사이(혼합)
predict(ridge.mod, s=05, type="coefficients")
predict(ridge.mod, s=10, type="coefficients")
predict(ridge.mod, s=5, type="coefficients")
predict(ridge.mod, s=20, type="coefficients") # s<-람다 No.
predict(ridge.mod, s=100, type="coefficients") # s<-람다 No.
predict(ridge.mod, s=1, type="coefficients") # s<-람다 No.
predict(ridge.mod, s=2, type="coefficients") # s<-람다 No.
predict(ridge.mod, s=5, type="coefficients") # s<-람다 No.
str(wine_red)
library(dplyr)
########################Red Wine###########################
wine_red = read.csv(file = 'hw/winequality-red.csv')
head(wine_red)
str(wine_red)
library(dplyr)
########################Red Wine###########################
wine_red = read.csv(file = 'hw/winequality-red.csv')
head(wine_red)
par(mfrow=c(1,2))
for (i in names(wine_red[,-12]))
{
boxplot(wine_red[,i] ~ quality, data = wine_red, xlab = 'Red Wine Quality', ylab = i, col=colors()[2:7])
}
setwd("~/GitHub/data_v")
library(dplyr)
########################Red Wine###########################
wine_red = read.csv(file = 'hw/winequality-red.csv')
head(wine_red)
par(mfrow=c(1,2))
for (i in names(wine_red[,-12]))
{
boxplot(wine_red[,i] ~ quality, data = wine_red, xlab = 'Red Wine Quality', ylab = i, col=colors()[2:7])
}
str(wine_red)
wine_red %>%
group_by(quality) %>%
summarize(mean = mean(alcohol),
median = median(alcohol),
var = var(alcohol),
min = min(alcohol),
max = max(alcohol)) %>% View()
